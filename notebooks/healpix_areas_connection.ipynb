{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e6f639-2455-4f5d-a557-b78b1d821ecf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# **Example Usage of Pangeo-Fish Software**\n",
    "\n",
    "\n",
    "**Overview:**\n",
    "This Jupyter notebook demonstrates the usage of the Pangeo-Fish software, a tool designed for analyzing biologging data in reference to Earth Observation (EO) data. Specifically, it utilizes data employed in the study conducted by M. Gonze et al. titled \"Combining acoustic telemetry with archival tagging to investigate the spatial dynamics of the understudied pollack *Pollachius pollachius*,\" accepted for publication in the Journal of Fish Biology.\n",
    "\n",
    "We showcase the application using the biologging tag 'A19124' attached to a pollack fish, along with reference EO data from the European Union Copernicus Marine Service Information (CMEMS) product 'NORTHWESTSHELF_ANALYSIS_FORECAST_PHY_004_013'. The biologging data consist of Data Storage Tag (DST) and teledetection by acoustic signals, along with release and recapture time and location of the species in question.  Both biologging data and the reference EO data are accessible with https and the access methods are incropolated in this notebook.   \n",
    "\n",
    "\n",
    "\n",
    "**Purpose:**\n",
    "By executing this notebook, users will learn how to set up a workflow for utilizing the Pangeo-Fish software. The workflow consists of 9 steps which are described below:\n",
    "\n",
    "1. **Configure the Notebook:** Prepare the notebook environment for analysis.\n",
    "2. **Compare Reference Model with DST Information:** Analyze and compare data from the reference model with information from the biologging data of the species in question. \n",
    "3. **Regrid the Grid from Reference Model Grid to Healpix Grid:** Transform the grid from the reference model to the Healpix grid for further analysis.\n",
    "4. **Construct Emission Matrix:** Create an emission matrix based on the transformed grid.\n",
    "5. **Compute Additional Emission Probability Matrix:** Calculate an additional emission probability matrix, particularly focusing on teledetection from acoustic signals.\n",
    "6. **Combine and Normalize Emission Matrix:** Merge the emission matrix and normalize it for further processing.\n",
    "7. **Estimate Model Parameters:** Determine the parameters of the model based on the normalized emission matrix.\n",
    "8. **Compute State Probabilities and Tracks:** Calculate the probability distribution of the species in question and compute the tracks.\n",
    "9. **Visualization:** Visualize the results of the analysis for interpretation and insight.\n",
    "\n",
    "Throughout this notebook, users will gain practical experience in setting up and executing a workflow using Pangeo-Fish, enabling them to apply similar methodologies to their own biologging data analysis tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535925e-793d-41be-a989-4fae4cdaaa67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1. **Configure the Notebook:** Prepare the notebook environment for analysis.\n",
    "\n",
    "In this step, we sets up the notebook environment for analysis. It includes installing necessary packages, importing required libraries, setting up parameters, and configuring the cluster for distributed computing. It also retrieves the tag data needed for analysis.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea188b-a3b6-4d00-9cf4-7c99c811f809",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules.\n",
    "import xarray as xr\n",
    "from pint_xarray import unit_registry as ureg\n",
    "from pangeo_fish.io import open_tag\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124e61e-2357-4870-b69a-646b628b2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Define a filter function to catch specific warnings\n",
    "def filter_warning(message, category, filename, lineno, file=None, line=None):\n",
    "    # Filter out the warning you want to hide\n",
    "    if \"Could not set timeout on TCP stream\" in str(message):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "warnings.showwarning = filter_warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0c569-0b64-407f-b167-bb9fe7ee4349",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Set up execution parameters for the analysis.\n",
    "#\n",
    "# Note: This cell is tagged as parameters, allowing automatic updates when configuring with papermil.\n",
    "\n",
    "# tag_name corresponds to the name of the biologging tag name (DST identification number), \n",
    "# which is also a path for storing all the information for the specific fish tagged with tag_name.\n",
    "# tag_name = \"AD_A11849\"\n",
    "tag_name = \"SV_A11957\"\n",
    "\n",
    "# tag_list = ['NO_A12710','LT_A11205','CB_A11036','LT_A11385','SQ_A10684','AD_A11177','PB_A12063','NO_A12742','DK_A10642','CB_A11071']\n",
    "# tag_name = tag_list[9]\n",
    "\n",
    "# tag_root specifies the root URL for tag data used for this computation.\n",
    "tag_root = \"cleaned\"\n",
    "\n",
    "# catalog_url specifies the URL for the catalog for reference data used.\n",
    "catalog_url = \"https://data-taos.ifremer.fr/kerchunk/ref-copernicus.yaml\"\n",
    "\n",
    "# scratch_root specifies the root directory for storing output files.\n",
    "scratch_root = \"s3://destine-gfts-data-lake/demo\"\n",
    "\n",
    "# storage_options specifies options for the filesystem storing output files.\n",
    "storage_options = {\n",
    "    'anon': False, \n",
    "    'profile' : \"gfts\",\n",
    "    'client_kwargs': {\n",
    "        \"endpoint_url\": \"https://s3.gra.perf.cloud.ovh.net\",\n",
    "        \"region_name\": \"gra\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# if you are using local file system, activate following two lines\n",
    "scratch_root = \"./track_generation/\"\n",
    "storage_options = None\n",
    "\n",
    "# Default chunk value for time dimension.  This values depends on the configuration of your dask cluster.\n",
    "chunk_time=24\n",
    "\n",
    "#\n",
    "# Parameters for step 2. **Compare Reference Model with DST Information:**\n",
    "#\n",
    "# bbox, bounding box, defines the latitude and longitude range for the analysis area.\n",
    "bbox = {\"latitude\": [42, 53], \"longitude\": [-8, 4]} \n",
    "\n",
    "# relative_depth_threshold defines the acceptable fish depth relative to the maximum tag depth.\n",
    "# It determines whether the fish can be considered to be in a certain location based on depth.\n",
    "relative_depth_threshold = 0.8\n",
    "\n",
    "#\n",
    "# Parameters for step 3. **Regrid the Grid from Reference Model Grid to Healpix Grid:** \n",
    "#\n",
    "# nside defines the resolution of the healpix grid used for regridding.\n",
    "nside = 4096 #*2\n",
    "\n",
    "# rot defines the rotation angles for the healpix grid.\n",
    "rot = {\"lat\": 0, \"lon\": 0}\n",
    "\n",
    "# min_vertices sets the minimum number of vertices for a valid transcription for regridding.\n",
    "min_vertices = 1\n",
    "\n",
    "#\n",
    "# Parameters for step 4. **Construct Emission Matrix:**\n",
    "#\n",
    "# differences_std sets the standard deviation for scipy.stats.norm.pdf.\n",
    "# It expresses the estimated certainty of the field of difference.\n",
    "differences_std = 0.75\n",
    "\n",
    "# recapture_std sets the covariance for recapture event.\n",
    "# It shows the certainty of the final recapture area if it is known.\n",
    "recapture_std = 1e-2\n",
    "\n",
    "# earth_radius defines the radius of the Earth used for distance calculations.\n",
    "earth_radius = ureg.Quantity(6371, \"km\")\n",
    "\n",
    "# maximum_speed sets the maximum allowable speed for the tagged fish.\n",
    "maximum_speed = ureg.Quantity(60, \"km / day\")\n",
    "\n",
    "# adjustment_factor adjusts parameters for a more fuzzy search.\n",
    "# It will factor the allowed maximum displacement of the fish.\n",
    "adjustment_factor = 5  \n",
    "\n",
    "# truncate sets the truncating factor for computed maximum allowed sigma for convolution process.\n",
    "truncate = 4\n",
    "\n",
    "#\n",
    "# Parameters for step 5. **Compute Additional Emission Probability Matrix:**\n",
    "#\n",
    "# receiver_buffer sets the maximum allowed detection distance for acoustic receivers.\n",
    "receiver_buffer = ureg.Quantity(1000, \"m\")\n",
    "\n",
    "#\n",
    "# Parameters for step 7. **Estimate Model Parameters:** \n",
    "#\n",
    "# tolerance sets the tolerance level for optimised parameter serarch computation.\n",
    "tolerance = 1e-3\n",
    "\n",
    "#\n",
    "# Parameters for step 8. **Compute State Probabilities and Tracks:** \n",
    "#\n",
    "# track_modes defines the modes for track calculation.\n",
    "track_modes = [\"mean\", \"mode\"]\n",
    "\n",
    "# additional_track_quantities sets quantities to compute for tracks using moving pandas.\n",
    "additional_track_quantities = [\"speed\", \"distance\"]\n",
    "\n",
    "\n",
    "#\n",
    "# Parameters for step 9. **Visualization:** \n",
    "#\n",
    "# time_step defines for each time_step value we visualize state and emission matrix. \n",
    "time_step = 3\n",
    "\n",
    "\n",
    "# Define target root directories for storing analysis results.\n",
    "target_root = f\"{scratch_root}/{tag_name}\"\n",
    "\n",
    "# Defines default chunk size for optimisation.  \n",
    "default_chunk = {\"time\": chunk_time, \"lat\": -1, \"lon\": -1}\n",
    "default_chunk_xy = {\"time\": chunk_time, \"x\": -1, \"y\": -1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268b5c0-b1e8-4d12-b6c9-b3b7aa54f99b",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up a local cluster for distributed computing.\n",
    "from distributed import LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9eff8-9313-4beb-9ae9-faa9515fd16e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Open and retrieve the tag data required for the analysis\n",
    "tag = open_tag(tag_root, tag_name)\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517857a8-f73f-4627-b628-32e8ed9f1046",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3. **Regrid the Grid from Reference Model Grid to Healpix Grid:** Transform the grid from the reference model to the Healpix grid for further analysis.\n",
    "\n",
    "In this step, we regrid the data from the reference model grid to a Healpix grid. This process involves defining the Healpix grid, creating the target grid, computing interpolation weights, performing the regridding, and saving the regridded data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d775f-73e5-40fc-8d3e-a50b342ccb3f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from xarray_healpy import HealpyGridInfo, HealpyRegridder\n",
    "from pangeo_fish.grid import center_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd261f-a25e-483f-9090-72ed65f621cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Open the diff data and performs cleaning operations to prepare it for regridding.\n",
    "\n",
    "ds = (\n",
    "    xr.open_dataset(f\"{target_root}/diff.zarr\", engine=\"zarr\", chunks={},\n",
    "                    storage_options=storage_options)\n",
    "    .pipe(lambda ds: ds.merge(ds[[\"latitude\", \"longitude\"]].compute()))\n",
    "    .swap_dims({\"lat\": \"yi\", \"lon\": \"xi\"})\n",
    "    .drop_vars([\"lat\", \"lon\"])\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bffa49-bd15-4263-8b13-b4e9c8b167a7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define the target Healpix grid information\n",
    "grid = HealpyGridInfo(level=int(np.log2(nside)), rot=rot)\n",
    "target_grid = grid.target_grid(ds).pipe(center_longitude, 0)\n",
    "target_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56410ac-7d35-478c-a201-cca8079032a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute the interpolation weights for regridding the diff data\n",
    "regridder = HealpyRegridder(\n",
    "    ds[[\"longitude\", \"latitude\", \"ocean_mask\"]],\n",
    "    target_grid,\n",
    "    method=\"bilinear\",\n",
    "    interpolation_kwargs={\"mask\": \"ocean_mask\", \"min_vertices\": min_vertices},\n",
    ")\n",
    "regridder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0516c5cd-cfc1-400c-803c-5a5850af3b49",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Perform the regridding operation using the computed interpolation weights.\n",
    "regridded = regridder.regrid_ds(ds)\n",
    "regridded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440d5b5-84ba-403e-86f6-14acc5850bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = grid.to_2d_bis(regridded,dim=\"cells\").pipe(center_longitude,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af227bde-f604-41ef-b148-67914baf08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped[\"diff\"].isel(time=0).hvplot.quadmesh(x=\"longitude\",y=\"latitude\",coastline=\"10m\",cmap=\"cool\",width=1000,height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9937de-9c4c-4169-9b0b-637102518458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_pixel(level, indices):\n",
    "    return indices >> (level * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a08f9f-e2d3-47b1-b355-b45a54e51fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filtering condition\n",
    "cond = base_pixel(grid.level, regridded[\"cell_ids\"]) == 0\n",
    "\n",
    "# using the function\n",
    "regridded_filtered = regridded.where(cond, other=0, drop=True)\n",
    "\n",
    "# Result\n",
    "regridded_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9b26e-9a9c-435f-bf61-1006da8ac1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reshape the regridded data to 2D\n",
    "reshaped_1 = grid.to_2d(regridded_filtered).pipe(center_longitude, 0)\n",
    "reshaped_1 = reshaped_1.persist()\n",
    "reshaped_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770ac48-e34f-4fe4-be36-6073d0c8923d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the filtering condition\n",
    "cond = base_pixel(grid.level, regridded[\"cell_ids\"]) == 3\n",
    "\n",
    "# using the function\n",
    "regridded_filtered = regridded.where(cond, other=0, drop=True)\n",
    "\n",
    "# Result\n",
    "regridded_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f9daa-3224-41b4-b012-7e0f94d2c895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reshape the regridded data to 2D\n",
    "reshaped_2 = grid.to_2d(regridded_filtered).pipe(center_longitude, 0)\n",
    "reshaped_2 = reshaped_2.persist()\n",
    "reshaped_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd63e02-3828-46ed-b232-c86ee8f12916",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(reshaped_1,reshaped_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f28e6-5f65-4c67-9af1-3af9c0f84b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_1[\"diff\"].isel(time=0).hvplot.quadmesh(x=\"longitude\",y=\"latitude\",coastline=\"10m\",cmap=\"cool\",width=1000,height=600,grid=True) * reshaped_2[\"diff\"].isel(time=0).hvplot.quadmesh(x=\"longitude\",y=\"latitude\",coastline=\"10m\",cmap=\"fire\",width=1000,height=600,grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713698c-1e41-4a61-8db4-2e25fe5e795d",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell verifies the regridded data by plotting the count of non-NaN values.\n",
    "reshaped[\"diff\"].count([\"x\", \"y\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc2531-c9cc-4d86-9714-89fcfb345d1e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# This cell saves the regridded data to Zarr format, then cleans up unnecessary variables to free up memory after the regridding process.  \n",
    "reshaped.chunk(default_chunk_xy).to_zarr(\n",
    "    f\"{target_root}/diff-regridded.zarr\",\n",
    "    mode=\"w\",\n",
    "    consolidated=True,\n",
    "    compute=True,\n",
    "    storage_options=storage_options,\n",
    ")\n",
    "# Cleanup unnecessary variables to free up memory\n",
    "del ds, grid, target_grid, regridder, regridded, reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b02c2-827e-4e0e-bf36-1e1a8187edcc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 4. **Construct Emission Matrix:** Create an emission matrix based on the transformed grid.\n",
    "\n",
    "In this step, we construct the emission probability matrix based on the differences between the observed tag temperature and the reference sea temperature computed in Workflow 2 and regridded in Workflow 3. The emission probability matrix represents the likelihood of observing a specific temperature difference given the model parameters and configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68e324-396d-4433-9955-b0ca96f9cd55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from toolz.dicttoolz import valfilter\n",
    "from pangeo_fish.distributions import create_covariances, normal_at\n",
    "from pangeo_fish.pdf import normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b5abc-e758-4512-adac-9108e8947ee8",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Open the regridded diff data \n",
    "differences = xr.open_dataset(\n",
    "    f\"{target_root}/diff-regridded.zarr\",\n",
    "    engine=\"zarr\",\n",
    "    chunks={},\n",
    "    storage_options=storage_options,\n",
    ").pipe(lambda ds: ds.merge(ds[[\"latitude\", \"longitude\"]].compute()))\n",
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfdc4e0-1a5b-48ac-82c1-3ce99fc3c8e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute initial and final position\n",
    "grid = differences[[\"latitude\", \"longitude\"]].compute()\n",
    "\n",
    "initial_position = tag[\"tagging_events\"].ds.sel(event_name=\"release\")\n",
    "cov = create_covariances(1e-6, coord_names=[\"latitude\", \"longitude\"])\n",
    "initial_probability = normal_at(\n",
    "    grid, pos=initial_position, cov=cov, normalize=True, axes=[\"latitude\", \"longitude\"]\n",
    ")\n",
    "\n",
    "final_position = tag[\"tagging_events\"].ds.sel(event_name=\"fish_death\")\n",
    "if final_position[[\"longitude\", \"latitude\"]].to_dataarray().isnull().all():\n",
    "    final_probability = None\n",
    "else:\n",
    "    cov = create_covariances(recapture_std**2, coord_names=[\"latitude\", \"longitude\"])\n",
    "    final_probability = normal_at(\n",
    "        grid,\n",
    "        pos=final_position,\n",
    "        cov=cov,\n",
    "        normalize=True,\n",
    "        axes=[\"latitude\", \"longitude\"],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c066be-cec3-4ab4-96aa-c557f8e00192",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#compute emission probability matrix\n",
    "\n",
    "emission_pdf = (\n",
    "    normal(differences[\"diff\"], mean=0, std=differences_std, dims=[\"y\", \"x\"])\n",
    "    .to_dataset(name=\"pdf\")\n",
    "    .assign(\n",
    "        valfilter(\n",
    "            lambda x: x is not None,\n",
    "            {\n",
    "                \"initial\": initial_probability,\n",
    "                \"final\": final_probability,\n",
    "                \"mask\": differences[\"ocean_mask\"],\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    .assign_attrs(differences.attrs )#| {\"max_sigma\": max_sigma})\n",
    ")\n",
    "\n",
    "emission_pdf=emission_pdf.chunk(default_chunk_xy).persist()\n",
    "emission_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe63b9d-dfdc-4370-8def-57a80efcb17c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Verify the data\n",
    "emission_pdf[\"pdf\"].count([\"x\", \"y\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ac6c2-68f7-4b4e-bb78-76d436058559",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_pdf[\"pdf\"].isel(time=0).hvplot.quadmesh(x='longitude',y='latitude',cmap=\"cool\",clim=(-2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59d9e9-95ad-4611-9eec-776fcb82c329",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell saves the emission data to Zarr format, then cleans up unnecessary variables to free up memory.\n",
    "\n",
    "emission_pdf.to_zarr(\n",
    "    f\"{target_root}/emission.zarr\", mode=\"w\", consolidated=True,\n",
    "    storage_options=storage_options,\n",
    ")\n",
    "\n",
    "\n",
    "del differences, grid, initial_probability, final_probability, emission_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff35d52d-6caa-4cab-92b7-d796020862a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 6. **Combine and Normalize Emission Matrix:** Merge the emission matrix and normalize it for further processing.\n",
    "\n",
    "In this step, we combine the emission probability matrix constructed in Workflow 4 and 5 then normalize it to ensure that the probabilities sum up to one. This step prepares the combined emission matrix for further analysis and interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5ca63d-35e9-4a55-af45-52cea678be17",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries \n",
    "from pangeo_fish.pdf import combine_emission_pdf\n",
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d5c93e-1045-4b57-a148-597a6bfc5727",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open and combine the emission probability matrix\n",
    "\n",
    "combined = (\n",
    "    xr.open_dataset(\n",
    "        f\"{target_root}/emission.zarr\",\n",
    "        engine=\"zarr\",\n",
    "        chunks=default_chunk_xy,\n",
    "        inline_array=True,\n",
    "        storage_options=storage_options          \n",
    "    )\n",
    "    .pipe(combine_emission_pdf)\n",
    "    .chunk(default_chunk_xy)\n",
    "    .persist()  # convert to comment if the emission matrix does *not* fit in memory\n",
    ")\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6b86e-1d62-402e-a72d-6604a66fa18d",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify the data and visualize the sum of probabilities\n",
    "combined[\"pdf\"].sum([\"x\", \"y\"]).hvplot(width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31505f9-122d-4280-9c29-7cea21cc6e1c",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the combined and normalized emission matrix\n",
    "combined.to_zarr(\n",
    "    f\"{target_root}/combined.zarr\", mode=\"w\", consolidated=True,\n",
    "    storage_options=storage_options    \n",
    ")\n",
    "del combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79d0a-c196-4cd1-9f3f-a7d745417dac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 7. **Estimate Model Parameters:** Determine the parameters of the model based on the normalized emission matrix.\n",
    "\n",
    "This step first estimates maxixmum allowed value of  model parameter 'sigma' max_sigma.  Then we\n",
    "create an optimizer with an expected parameter range, fitting the model to the normalized emission matrix.  \n",
    "The resulting optimized parameters is saved to a json file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8335be-41d5-470b-bee7-8f9d09db5e1f",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules for data analysis.\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pangeo_fish.hmm.estimator import EagerScoreEstimator\n",
    "from pangeo_fish.hmm.optimize import EagerBoundsSearch\n",
    "from pangeo_fish.utils import temporal_resolution\n",
    "# Open the data\n",
    "emission = (\n",
    "    xr.open_dataset(\n",
    "        f\"{target_root}/combined.zarr\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "        inline_array=True,\n",
    "        storage_options=storage_options            \n",
    "    )\n",
    ")\n",
    "emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccac4fe-cf28-403c-a00b-b78b8cf0e0be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute maximum displacement for each reference model time step\n",
    "# and estimate maximum sigma value for limiting the optimisation step\n",
    "\n",
    "earth_radius_ = xr.DataArray(earth_radius, dims=None)\n",
    "\n",
    "timedelta = temporal_resolution(emission[\"time\"]).pint.quantify().pint.to(\"h\")\n",
    "grid_resolution = earth_radius_ * emission[\"resolution\"].pint.quantify()\n",
    "\n",
    "maximum_speed_ = xr.DataArray(maximum_speed, dims=None).pint.to(\"km / h\")\n",
    "max_grid_displacement = maximum_speed_ * timedelta * adjustment_factor / grid_resolution\n",
    "max_sigma = max_grid_displacement.pint.to(\"dimensionless\").pint.magnitude / truncate\n",
    "emission.attrs[\"max_sigma\"]=max_sigma\n",
    "max_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bffb27-7bb0-4a3d-abd1-ab7d41d80f4a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and configure estimator and optimizer\n",
    "emission = emission.compute()  # Convert to comment if the emission matrix does *not* fit in memory\n",
    "estimator = EagerScoreEstimator()\n",
    "optimizer = EagerBoundsSearch(\n",
    "    estimator,\n",
    "    (1e-4, emission.attrs[\"max_sigma\"]),\n",
    "    optimizer_kwargs={\"disp\": 3, \"xtol\": tolerance},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706e4c4-6825-4640-96db-3b721197ff12",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the model parameter to the data\n",
    "optimized = optimizer.fit(emission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d228ec-3653-4aac-a58b-630a1f436f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized parameters\n",
    "params=optimized.to_dict()\n",
    "pd.DataFrame.from_dict(params, orient='index').to_json(f\"{target_root}/parameters.json\", \n",
    "                                                               storage_options=storage_options    )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763d257-f9cd-40e6-8847-56afca0cae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del optimized,  emission "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2795b7d-c67f-494d-a337-4640e496f606",
   "metadata": {},
   "source": [
    "## 8. **Compute State Probabilities and Tracks:** Calculate the probability distribution of the species in question and compute the tracks.\n",
    "\n",
    "This step involves predicting state probabilities using the optimised parameter sigma computed in the last step together with normalized emission matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ec27c-bb42-43de-8138-8f2f878c73be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules for data analysis.\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import hvplot.xarray\n",
    "from pangeo_fish.hmm.estimator import EagerScoreEstimator\n",
    "from pangeo_fish.io import save_trajectories\n",
    "\n",
    "# Recreate the Estimator\n",
    "params=pd.read_json(f\"{target_root}/parameters.json\", storage_options=storage_options    ).to_dict()[0]\n",
    "optimized = EagerScoreEstimator(**params)\n",
    "optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471abe4-5e9a-4402-b9dd-8e8a9463ef05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load the Data\n",
    "emission = (\n",
    "    xr.open_dataset(\n",
    "        f\"{target_root}/combined.zarr\",\n",
    "        engine=\"zarr\",\n",
    "        chunks=default_chunk_xy,\n",
    "        inline_array=True,\n",
    "        storage_options=storage_options            \n",
    "    ).compute()\n",
    ")\n",
    "\n",
    "# Predict the State Probabilities\n",
    "\n",
    "states = optimized.predict_proba(emission)\n",
    "states = states.to_dataset().chunk(default_chunk_xy).persist()\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54bd04-6a87-4103-815b-83fa1ed48562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data and visualize the sum of probabilities\n",
    "states.sum([\"x\", \"y\"]).hvplot() +states.count([\"x\", \"y\"]).hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75e225-7026-41a9-9af2-30e032b658e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save probability distirbution, state matrix.  \n",
    "states.chunk(default_chunk_xy).to_zarr(\n",
    "    f\"{target_root}/states.zarr\", mode=\"w\", consolidated=True,  \n",
    "        storage_options=storage_options                \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d11d3-47ba-42d4-9c20-5161c20a9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717295b0-ab13-4b39-8439-f3dfdddb21a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission[\"pdf\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66289339-fc81-4947-a64e-ff36c1d14b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#decode tracks\n",
    "\n",
    "trajectories = optimized.decode(\n",
    "    emission,\n",
    "    states.fillna(0),\n",
    "    mode=track_modes,\n",
    "    progress=False,\n",
    "    additional_quantities=additional_track_quantities,\n",
    ")\n",
    "trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcad62-73c3-437c-997a-a01cf0e5ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trajectories. \n",
    "# Here we can chose format parquet for loading files from 'R'\n",
    "# or chose to  format 'geoparquet' for further analysis of tracks using \n",
    "# geopands. \n",
    "\n",
    "save_trajectories(trajectories, target_root,storage_options, format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46330036-1044-4820-91ad-2324bc66edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del optimized,  emission, states, trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b55dbb-d709-4297-af4e-d527d03c2a99",
   "metadata": {},
   "source": [
    "## 9. **Visualization:** Visualize the results of the analysis for interpretation and insight.\n",
    "\n",
    "\n",
    "In this step, we visualize various aspects of the analysis results to gain insights and interpret the model outcomes. We plot the emission matrix, which represents the likelihood of observing a specific temperature difference given the model parameters and configurations. Additionally, we visualize the state probabilities, showing the likelihood of the system being in different states at each time step. We also plot each of the tracks of the tagged fish, displaying their movement patterns over time. Finally, we create a movie that combines the emission matrix and state probabilities to provide a comprehensive visualization of the analysis results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95116a3-2fac-4457-bd2e-5e103bab4f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import holoviews as hv\n",
    "import hvplot.xarray\n",
    "import cmocean\n",
    "import xmovie\n",
    "from pangeo_fish import visualization\n",
    "from pangeo_fish.io import read_trajectories, save_html_hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de587ce-0064-4b27-a0ea-d6cc35e685a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trajectories \n",
    "trajectories = read_trajectories( track_modes,target_root,storage_options, format=\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a2063-17ff-4085-9ce9-2b9d27984472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectoriesand plot.  \n",
    "\n",
    "plots = [\n",
    "    traj.hvplot(c=\"speed\", tiles=\"CartoLight\", title=traj.id, cmap=\"cmo.speed\"\n",
    "#                ,xlim=bbox['longitude'],        ylim=bbox['latitude']\n",
    "                ,width=300,height=300)\n",
    "    for traj in trajectories.trajectories\n",
    "]\n",
    "plot=hv.Layout(plots).cols(2)\n",
    "\n",
    "filepath = f\"{target_root}/trajectories.html\"\n",
    "save_html_hvplot(plot, filepath, storage_options)\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cc66f-9b49-4eac-a907-e5ed2d9834d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load files for plotting\n",
    "\n",
    "emission = (\n",
    "    xr.open_dataset(\n",
    "        f\"{target_root}/combined.zarr\",\n",
    "        engine=\"zarr\",\n",
    "        chunks={},\n",
    "        inline_array=True,\n",
    "        storage_options=storage_options,\n",
    "    )\n",
    "    .rename_vars({\"pdf\": \"emission\"})\n",
    "    .drop_vars([\"final\", \"initial\"])\n",
    ")#.where(emission[\"mask\"])\n",
    "states = (\n",
    "    xr.open_dataset(\n",
    "        f\"{target_root}/states.zarr\", \n",
    "        engine=\"zarr\", \n",
    "        chunks={}, \n",
    "        inline_array=True,\n",
    "        storage_options=storage_options,\n",
    "    ).where(emission[\"mask\"])\n",
    ")\n",
    "data = xr.merge([states, emission.drop_vars([\"mask\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd47a3-bc01-4fd5-a2cf-57851f2ec9ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# visualize states and emission matrix.  Save the visualisation in an html file.  \n",
    "# \n",
    "plot1 = visualization.plot_map(data[\"states\"],bbox)\n",
    "plot2 = visualization.plot_map(data[\"emission\"],bbox)\n",
    "plot=hv.Layout([plot1, plot2]).cols(2)\n",
    "filepath = f\"{target_root}/states_emission.html\"\n",
    "\n",
    "save_html_hvplot(plot, filepath, storage_options)\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b9b5d-3c1e-41d0-a21d-07cc43060ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Create Movies \n",
    "#\n",
    "mov = xmovie.Movie(\n",
    "    (data\n",
    "     .isel(time=slice(0,data.time.size-1,time_step))\n",
    "     .chunk({\"time\": 1, \"x\": -1, \"y\": -1})\n",
    "     .pipe(lambda ds: ds.merge(ds[[\"longitude\", \"latitude\"]].compute())))\n",
    "    .pipe(\n",
    "        visualization.filter_by_states\n",
    "    ),\n",
    "    plotfunc=visualization.create_frame,\n",
    "    input_check=False,\n",
    "    pixelwidth=15 * 400,\n",
    "    pixelheight=12 * 400,\n",
    "    dpi=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca3a2d-77bf-40fc-aee8-8a7f35fc7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with s3fs, this does not work due to https://github.com/jbusecke/xmovie/issues/162\n",
    "# use local file system\n",
    "#!mkdir movie\n",
    "#mov.save(f\"./movie/states.mp4\", parallel=True, overwrite_existing=True, )\n",
    "mov.save(f\"{target_root}/states.mp4\", parallel=True, overwrite_existing=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f648a-f6e1-40f7-9bc7-970d6de7a80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-fish",
   "language": "python",
   "name": "pangeo-fish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
